{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1286cef-0fa4-4cda-8cda-a26a0f0a59a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboardX\n",
      "  Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\envs\\bert_env\\lib\\site-packages (from tensorboardX) (1.26.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\envs\\bert_env\\lib\\site-packages (from tensorboardX) (23.1)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\admin\\anaconda3\\envs\\bert_env\\lib\\site-packages (from tensorboardX) (4.25.1)\n",
      "Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.6.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49fc9306-6edc-436a-b6ac-dccb0165b5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      " 27 34908   27  9646    0     0  21736      0  0:00:01 --:--:--  0:00:01 21774\n",
      "100 34908  100 34908    0     0  76763      0 --:--:-- --:--:-- --:--:-- 76889\n"
     ]
    }
   ],
   "source": [
    "!curl -L -O https://raw.githubusercontent.com/huggingface/transformers/main/examples/legacy/question-answering/run_squad.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad8325b-8aa1-4c2f-a91a-ed99ea54f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e0c25a-9f9d-4347-800c-35ec5ad75ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f049ff70-969f-407d-b374-565b0331859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "python run_squad.py --model_type bert --model_name_or_path bert-base-multilingual-uncased  --do_eval --do_lower_case --train_file cache_bert/train-v2.0.json --predict_file cache_bert/dev-v2.0.json --version_2_with_negative --max_seq_length 400 --doc_stride 128 --output_dir output_bert/ --per_gpu_eval_batch_size=8 --save_steps=400 --cache_dir cache_bert/ \n",
    "\n",
    "python -m torch.distributed.launch --nproc_per_node=2 ./examples/run_squad.py --model_type bert --model_name_or_path bert-base-multilingual-uncased --do_train --do_eval --do_lower_case --train_file dataset/train-v2.0.json --predict_file dataset/dev-v2.0.json --version_2_with_negative --learning_rate 3e-5 --num_train_epochs 2 --max_seq_length 430 --doc_stride 128 --output_dir output_bert/ --per_gpu_eval_batch_size=8 --per_gpu_train_batch_size=8 --gradient_accumulation_steps=3 --save_steps=400 --cache_dir cache_bert/ \n",
    "\n",
    "python -m torch.distributed.launch --nproc_per_node=2 ./examples/run_squad.py --model_type bert --model_name_or_path bert-base-multilingual-uncased --do_train --do_eval --do_lower_case --train_file dataset/train-v2.0.json --predict_file dataset/dev-v2.0.json --version_2_with_negative --learning_rate 3e-5 --num_train_epochs 3 --max_seq_length 430 --doc_stride 128 --output_dir output_bert/ --per_gpu_eval_batch_size=8 --per_gpu_train_batch_size=8 --gradient_accumulation_steps=3 --save_steps=200 --cache_dir cache_bert/\n",
    "\n",
    "python ./examples/run_squad.py --model_type bert --model_name_or_path bert-base-multilingual-uncased  --do_eval --do_lower_case --eval_all_checkpoints --train_file dataset/train-v2.0.json --predict_file dataset/dev-v2.0.json --version_2_with_negative --max_seq_length 430 --doc_stride 128 --output_dir output_bert/ --per_gpu_eval_batch_size=8 --cache_dir cache_bert/ --n_best_size 1\n",
    "\n",
    "#run viet mai long\n",
    "python ./examples/run_squad.py --model_type bert --model_name_or_path checkpoint-7000/ --do_train --do_eval --do_lower_case --evaluate_during_training --train_file dataset/train-v2.0-viet_mailong.json --predict_file dataset/dev-v2.0-viet_mailong.json --version_2_with_negative --learning_rate 2e-5 --num_train_epochs 2 --max_seq_length 400 --doc_stride 128 --output_dir output_bert/ --per_gpu_eval_batch_size=8 --per_gpu_train_batch_size=6 --gradient_accumulation_steps=4 --logging_steps 50 --save_steps=1000 --cache_dir cache_bert/ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
