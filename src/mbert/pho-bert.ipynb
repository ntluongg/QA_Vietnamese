{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7347847,"sourceType":"datasetVersion","datasetId":4189628},{"sourceId":7373571,"sourceType":"datasetVersion","datasetId":4283385}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/datquocnguyen/transformers","metadata":{"execution":{"iopub.status.busy":"2024-01-10T02:54:17.552368Z","iopub.execute_input":"2024-01-10T02:54:17.553076Z","iopub.status.idle":"2024-01-10T02:55:03.878384Z","shell.execute_reply.started":"2024-01-10T02:54:17.553043Z","shell.execute_reply":"2024-01-10T02:55:03.877310Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/datquocnguyen/transformers\n  Cloning https://github.com/datquocnguyen/transformers to /tmp/pip-req-build-tmytc3cz\n  Running command git clone --filter=blob:none --quiet https://github.com/datquocnguyen/transformers /tmp/pip-req-build-tmytc3cz\n  Resolved https://github.com/datquocnguyen/transformers to commit 83cb6dab92114f8772a0f3d955b58bcb039dfb06\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.19.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (2.31.0)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.32.0.dev0)\n  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.32.0.dev0) (2023.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.32.0.dev0) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.32.0.dev0) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (2023.11.17)\nBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers: filename=transformers-4.32.0.dev0-py3-none-any.whl size=7416891 sha256=651a16ddc0f266b7c96c152c3c054324c44292681f4b807d23a6a3614794ffd8\n  Stored in directory: /tmp/pip-ephem-wheel-cache-hhagqjqm/wheels/ec/de/d3/b85b059f0443ad370d97c246854699ae9c0c0682114c46f174\nSuccessfully built transformers\nInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.0\n    Uninstalling tokenizers-0.15.0:\n      Successfully uninstalled tokenizers-0.15.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.36.0\n    Uninstalling transformers-4.36.0:\n      Successfully uninstalled transformers-4.36.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.14.3 requires transformers>=4.33.1, but you have transformers 4.32.0.dev0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tokenizers-0.13.3 transformers-4.32.0.dev0\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments,Trainer\nimport os\n\nimport datasets\nfrom torch.utils.data import DataLoader\nimport torch\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-01-10T02:55:03.880242Z","iopub.execute_input":"2024-01-10T02:55:03.880554Z","iopub.status.idle":"2024-01-10T02:55:19.661740Z","shell.execute_reply.started":"2024-01-10T02:55:03.880525Z","shell.execute_reply":"2024-01-10T02:55:19.660962Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertForQuestionAnswering, PhobertTokenizerFast, AutoModelForQuestionAnswering\n\ntokenizer = PhobertTokenizerFast.from_pretrained(\"vinai/phobert-base\")\nmodel = AutoModelForQuestionAnswering.from_pretrained(\"/kaggle/input/phobert-finetuned/phobert_tuned_vn/phobert_tuned_vn\")","metadata":{"execution":{"iopub.status.busy":"2024-01-10T02:55:19.662860Z","iopub.execute_input":"2024-01-10T02:55:19.663449Z","iopub.status.idle":"2024-01-10T02:55:25.392783Z","shell.execute_reply.started":"2024-01-10T02:55:19.663402Z","shell.execute_reply":"2024-01-10T02:55:25.391977Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"140713973a69476cb18d1c26a3f75d82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6e76182e10e41be88aae717c2eb9090"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.13M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80bee47f33d34c6db164082da76026a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23b14d7b999245dd9dfa90e892dc081a"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.is_fast","metadata":{"execution":{"iopub.status.busy":"2024-01-10T02:55:25.395578Z","iopub.execute_input":"2024-01-10T02:55:25.396441Z","iopub.status.idle":"2024-01-10T02:55:25.402794Z","shell.execute_reply.started":"2024-01-10T02:55:25.396401Z","shell.execute_reply":"2024-01-10T02:55:25.401637Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"max_length = tokenizer.model_max_length\nstride = 128","metadata":{"execution":{"iopub.status.busy":"2024-01-10T02:55:25.404071Z","iopub.execute_input":"2024-01-10T02:55:25.404415Z","iopub.status.idle":"2024-01-10T02:55:25.419875Z","shell.execute_reply.started":"2024-01-10T02:55:25.404382Z","shell.execute_reply":"2024-01-10T02:55:25.419174Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from transformers import EvalPrediction\nfrom sklearn.metrics import accuracy_score, f1_score\n\ndef compute_metrics(pred: EvalPrediction):\n    #print(pred)\n    start_positions = pred.label_ids[0]\n    start_predictions = pred.predictions[0].argmax(-1)\n    end_positions = pred.label_ids[1]\n    end_predictions = pred.predictions[1].argmax(-1)\n    print('label',start_positions,'\\n predict',end_predictions)\n    \n    # Compute Exact Match (EM) score\n    em_score = sum([1 if sp == lp and ep == le else 0 for sp, ep, lp, le in zip(start_predictions, end_predictions, start_positions, end_positions)]) / len(start_positions)\n    \n    f1_start = f1_score(start_positions, start_predictions, average='macro')\n    f1_end = f1_score(end_positions, end_predictions, average='macro')\n    return {\n        'f1_start': f1_start,\n        'f1_end': f1_end,\n        'f1': min(f1_start, f1_end),\n        'em_score': em_score  # Exact Match score\n    }\n\n\ndef tokenize_function(example):\n    encoding = tokenizer(example['context'], example['question'], truncation=True, padding='max_length',\n                         max_length=tokenizer.model_max_length\n                        )\n    start_positions = encoding.char_to_token(example['answer_start_idx'])\n    end_idx = example['answer_start_idx'] + len(example['answer_text']) - 1\n    end_positions = encoding.char_to_token(max(0, end_idx))\n    if start_positions is None:\n        start_positions = tokenizer.model_max_length\n    if end_positions is None:\n        end_positions = tokenizer.model_max_length\n    if (len(example['answer_text']) == 0):\n        start_positions = tokenizer.model_max_length\n        end_positions = tokenizer.model_max_length\n    return {'input_ids': encoding['input_ids'],\n          'attention_mask': encoding['attention_mask'],\n          'start_positions': start_positions,\n          'end_positions': end_positions}\n\n\ndef get_dataloader(train_path, valid_path, num_proc=10):\n    train_set = datasets.load_from_disk(train_path)\n    valid_set = datasets.load_from_disk(valid_path)\n    print(\"Train set: \", len(train_set))\n    print(\"Valid set: \", len(valid_set))\n\n    # Filter out examples that are longer than the tokenizer's max length\n    train_set = train_set.filter(lambda example: len(tokenizer(example['context'], truncation=False)['input_ids']) <= tokenizer.model_max_length)\n    valid_set = valid_set.filter(lambda example: len(tokenizer(example['context'], truncation=False)['input_ids']) <= tokenizer.model_max_length)\n    \n#     # Filter out examples that have empty answers\n#     train_set = train_set.filter(lambda example: len(example[\"answer_text\"]) > 0)\n#     valid_set = valid_set.filter(lambda example: len(example[\"answer_text\"]) > 0)\n\n    train_set = train_set.shuffle().map(tokenize_function, batched=False, num_proc=num_proc)\n    valid_set = valid_set.map(tokenize_function, batched=False, num_proc=num_proc)\n    \n    print(\"Train set: \", len(train_set))\n    print(\"Valid set: \", len(valid_set))\n    return train_set, valid_set","metadata":{"execution":{"iopub.status.busy":"2024-01-10T02:55:25.421310Z","iopub.execute_input":"2024-01-10T02:55:25.421613Z","iopub.status.idle":"2024-01-10T02:55:25.438583Z","shell.execute_reply.started":"2024-01-10T02:55:25.421587Z","shell.execute_reply":"2024-01-10T02:55:25.437780Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n\nprint(model)\nprint(model.config)\n\ntrain_dataset, valid_dataset = get_dataloader(\n    train_path='/kaggle/input/squadv2/processed/train.dataset',\n    valid_path='/kaggle/input/squadv2/processed/valid.dataset'\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T02:55:25.439750Z","iopub.execute_input":"2024-01-10T02:55:25.440117Z","iopub.status.idle":"2024-01-10T02:55:50.339422Z","shell.execute_reply.started":"2024-01-10T02:55:25.440084Z","shell.execute_reply":"2024-01-10T02:55:50.338283Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"RobertaForQuestionAnswering(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n      (position_embeddings): Embedding(258, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n)\nRobertaConfig {\n  \"_name_or_path\": \"/kaggle/input/phobert-finetuned/phobert_tuned_vn/phobert_tuned_vn\",\n  \"architectures\": [\n    \"RobertaForQuestionAnswering\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 258,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"tokenizer_class\": \"PhobertTokenizer\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.32.0.dev0\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 64001\n}\n\nTrain set:  19136\nValid set:  736\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6532d9266f646cca340168a1e935b4c"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (318 > 256). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a19b38c08b2d4992b634e44a472a4abe"}},"metadata":{}},{"name":"stdout","text":"              ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1275 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40bbfd71bd874e2da9f2ce3b15e0a069"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1275 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2a7265ab4c247d684655ca9436d92bf"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1274 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81e4decc0372430f9511e9035e6a8982"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1275 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3d2d42e909f4ad7aaee7ddb66a86bab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#4:   0%|          | 0/1274 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1cabc00a0554be7a55851a04bcceb1e"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#6:   0%|          | 0/1274 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d7248fdb14746e9b4753afed6e6278f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#5:   0%|          | 0/1274 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"018d0758273d47b0b2623470d3889b82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#7:   0%|          | 0/1274 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f3c0890c76640928741cb8bc9b4ab13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#8:   0%|          | 0/1274 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d173390371244d588f28685474e4daa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#9:   0%|          | 0/1274 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d1e84ce953e48e7b3791f393c95de6b"}},"metadata":{}},{"name":"stdout","text":"              ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/57 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17386dd468cf45fe98c942bdff874f68"}},"metadata":{}},{"name":"stdout","text":"    ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/57 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb7d25f7a2db4ca0830048e52434bf1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/57 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdc52fc6c95a484fa7c60f233b176f14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/57 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f846d4490e9c4631812be234cd37034f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#5:   0%|          | 0/57 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e50de2e7824478cb2e3c0218be44da2"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#4:   0%|          | 0/57 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18e14e8cb0dc4f31bdefe4f4ce914a46"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#7:   0%|          | 0/56 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34125981d17145c8ae26ac6bff37aa12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#6:   0%|          | 0/56 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1546ff843834479eb1a17a40a06f7030"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#8:   0%|          | 0/56 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee02fef2d3a74a3280afafd53cf65a50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#9:   0%|          | 0/56 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ebd975d37344a58b8d42db9fa15f855"}},"metadata":{}},{"name":"stdout","text":"Train set:  12743\nValid set:  566\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T02:55:50.341399Z","iopub.execute_input":"2024-01-10T02:55:50.342249Z","iopub.status.idle":"2024-01-10T02:55:50.347372Z","shell.execute_reply.started":"2024-01-10T02:55:50.342203Z","shell.execute_reply":"2024-01-10T02:55:50.346395Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['context', 'question', 'answer_text', 'answer_start_idx', 'answer_word_start_idx', 'answer_word_end_idx', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n    num_rows: 12743\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\"/kaggle/working/model-bin/test\",\n                                  num_train_epochs= 5, # 8, #10,\n                                  learning_rate=1e-5, #1e-4\n                                  warmup_ratio=0.05,\n                                  weight_decay=0.01,\n                                  per_device_train_batch_size=4,\n                                  per_device_eval_batch_size=4,\n                                  gradient_accumulation_steps=1,\n                                  logging_dir='/kaggle/working/log',\n                                  logging_steps=5,\n                                  group_by_length=True, \n                                  save_strategy=\"epoch\",\n                                  metric_for_best_model='f1',\n                                  save_total_limit=2,\n                                  #remove_unused_columns=False, #this is IMPORTANT: not to get error\n                                  #eval_steps=200,\n                                  load_best_model_at_end=True,\n                                  #save_steps=200,\n                                  evaluation_strategy=\"epoch\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T02:55:50.348971Z","iopub.execute_input":"2024-01-10T02:55:50.349314Z","iopub.status.idle":"2024-01-10T02:55:50.564843Z","shell.execute_reply.started":"2024-01-10T02:55:50.349282Z","shell.execute_reply":"2024-01-10T02:55:50.563918Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from transformers import DefaultDataCollator\n\ndata_collator = DefaultDataCollator()","metadata":{"execution":{"iopub.status.busy":"2024-01-10T02:55:50.568381Z","iopub.execute_input":"2024-01-10T02:55:50.568696Z","iopub.status.idle":"2024-01-10T02:55:50.573437Z","shell.execute_reply.started":"2024-01-10T02:55:50.568669Z","shell.execute_reply":"2024-01-10T02:55:50.572508Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset,\n    data_collator=data_collator,\n    compute_metrics = compute_metrics\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-01-10T02:55:50.574676Z","iopub.execute_input":"2024-01-10T02:55:50.574997Z","iopub.status.idle":"2024-01-10T03:40:30.145390Z","shell.execute_reply.started":"2024-01-10T02:55:50.574948Z","shell.execute_reply":"2024-01-10T03:40:30.144282Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240110_025613-y4k2j0t9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ntluong/huggingface/runs/y4k2j0t9' target=\"_blank\">snowy-disco-60</a></strong> to <a href='https://wandb.ai/ntluong/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ntluong/huggingface' target=\"_blank\">https://wandb.ai/ntluong/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ntluong/huggingface/runs/y4k2j0t9' target=\"_blank\">https://wandb.ai/ntluong/huggingface/runs/y4k2j0t9</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='7965' max='7965' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [7965/7965 43:44, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1 Start</th>\n      <th>F1 End</th>\n      <th>F1</th>\n      <th>Em Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.879400</td>\n      <td>0.819185</td>\n      <td>0.586687</td>\n      <td>0.701700</td>\n      <td>0.586687</td>\n      <td>0.704947</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.928900</td>\n      <td>0.797870</td>\n      <td>0.623819</td>\n      <td>0.724272</td>\n      <td>0.623819</td>\n      <td>0.733216</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.605500</td>\n      <td>0.884592</td>\n      <td>0.650010</td>\n      <td>0.745891</td>\n      <td>0.650010</td>\n      <td>0.745583</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.308800</td>\n      <td>0.903780</td>\n      <td>0.639545</td>\n      <td>0.752617</td>\n      <td>0.639545</td>\n      <td>0.743816</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.003400</td>\n      <td>0.980593</td>\n      <td>0.645252</td>\n      <td>0.749641</td>\n      <td>0.645252</td>\n      <td>0.752650</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"label [  4  12  33  80  74  18  13  14  28  17  26   1   3  24  39  85  29  25\n   7  16   7  11  34   4  14  19  28   1  22  42  69  80  24  59  17  91\n  51   1  23  44   2  77   1  25  17   6  15   1  22  14   1  30   1  51\n  31  33  51   2  29   1  11  38  11  45  22  17  14   8   8   1  27  14\n   4  20  10  28   1  19  37  13   1  19  19  18  14   6  29  24  17   4\n   1  26  62   1   4  31  13  19   9   1  76  16  31  50  16  48  14  55\n   9   1  27  12  14  12  31  38  48  32  22  14  16  50 136  13  11  23\n   3   1   1   3   8  35  86   7   1   1 150  48  18   7   1  36  51  19\n  26   1   5   5  12   1  39   3  11   1   9   1  57   7  16  40   1   2\n  41   7  28   6   1  44   3  11   9  36   1  44   4   5   1  48   1   1\n  16  12  18 108  53   9  27   7   5  35  15 204   1  39  47  11  10  35\n  31  29   5   1   9  16  23   5   9  31  54   2  29  29  36  12  24  37\n   3  23   1  31  18  23  28   3  14  88  13  18  12  42   3  52  74  66\n  43  23  51  57  49  11  52  14  66   7  28  24 117  11   8   1  21   5\n  20  38  28   9  11   1  19  11  26  43  41  19  41  20  12  19   7  60\n   1  11   4   5  29   6  10  13  27   7  47  47   8   1  35  36   5  12\n  11   1  16  29  47   1   1   9  52  15  27  19  42  31   4   1   1   1\n  20  28   1  47  28  35   1  29  14  41   1  31   1  23  15   1   6  48\n   7   9   1  10  16  62  31   1   1   1  39  49  30  14   9  12  44   3\n  24  13  48  11  15   1  19   1  40  49  50 118  77   1   7  13  27   1\n   6   1  27  21   7  12   1  30   4  18   5  24   2   2  31  16  30  14\n  37  16  23  25  10  42  62  19  32  18  92  47  39   8  22   1   7  13\n  17   7   6  33   4   2  19  25   1   1  22  10  10  12  31   6  39   8\n 104   1   4  47  27   1   1  16  51  20  28  37  22  17  86  87  17   1\n  50   1   1   3   7   6   1   1  27  38  29  36  35   5   9   7  28  11\n  29  12   9  32   8  69  54   8  36  14   1  35  18   9  24 103  12   1\n 120   1  19   1   1  57   1  29   1   9   1  24  27  55   3  38   8  33\n   1   5   4  18  43  21   1  99  31  11  35  26  23  57  12  25   5   1\n  12   9   6  57   1   1   3  22   8  22  53  23  12   5 104  80  41  23\n  36  18  29  21  28   1  34   1  42  22  40  21   1  19   1  13  80  23\n   1  10  24  34  29  23  28  18   1  31  11  24  16  26  12  26   1  34\n  55   1   1  16  19   1  12   5] \n predict [ 10  14  33  81  77  20  14  30  30  18  27   3   6  25  40  88  31  13\n   8  18  10  11  36   7  15  20  29   2  65  43  74  83  25  62  18  92\n  51   3  24  17   7  78   2  27  19  17  15   3   7  15   3  34   3  51\n  32  36  52   3  33   5  13  43  14  17  26  20  22   9  17   4  27  16\n   5   5  12  30   3  20  38  15   2  21  20  21  45   8  31  24  31   5\n   2  27  63   1   6  33  14  20  10   2  81  18  32  51  16  43  15  33\n  25   7  27  16  14  14  33  16  49  34  23  16  17  52 138  15  12  25\n   5   6   2   4   6  25  90   8   2   5   3  48  19   9   4  37  51  20\n  27   5   7  10  14   3  42   4  13   2  10   3  57   7  18  19   6   5\n  43   9   2   9   2  44   5  14  14  38   3  44   5   6   1 104   2   3\n  20  14  19 109  54  12  30  14   6  36  13 194   4  41  48  11  11  35\n  32  30   8   2  11  18  24  10  11  34  57 107  43  30  38  15  25  39\n   4   2   2  63  20  24  29   3  14  93  15  20  15  42   4   6  76  76\n  45  25  52  58  52  12  53  15  67   9  23   2  16   2  10   3  22   6\n  22  40  28  10  12   3  20  12  28  45  41  22  45  21  13  21   8  62\n   3  12   7   6  30  10  14  14  28  12  49  48  10   3  35  37   9  23\n  13   2  18  31  48   2   3  11  53  19  28  20  44  33   8  39   2   2\n  22  34   3  48  23  37   1  31  19  43   5  36   3  25  17   7  22  49\n   9  11   3  16  17  69  32   3   3   3  40  51  33  15  21  13  44   4\n  24  18  49  13  15   2  23   5  40  52  51 119  79   1  12  13  12   3\n  11   2  28  25   9  13   2  31   4  20   8  26   3   5  36  20  31  15\n  38  18  23  26  13  43  63  24  34  19  94  48  42  10  24   3   8  10\n  12   9   8  33  10   6  19  27   2   3  23  11  13  18   9  17  39   9\n 107   4   5  49  30   3   3  17  52  21  40  40  31  17  88  13  21   2\n  52   2   4  13  13  29  77   2  29  38  33  38  37   9  11   9  30  12\n  31  13  10  34   9   3  63  14  37  24   3  36   6  13  24 105  14   3\n  92   4  26   3   2  58   3  30   3  11   3  26  29  57   4  38  10  37\n   3   6   6  20  38  22   2 101  32  13  38  28  25  58  14  26  11   3\n  41  10  29  59   2   4  14  24   9  23   4  16  14   6  10   2  43  26\n  48  20  31  22  32   2  35   2  43  23  42  23   4  21   3  15  57  25\n   4  11  22  37  33  26  29  22   6  32  12  25  17  17  13   5   3  34\n  56   2   9  17  20   3  17   5]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"label [  4  12  33  80  74  18  13  14  28  17  26   1   3  24  39  85  29  25\n   7  16   7  11  34   4  14  19  28   1  22  42  69  80  24  59  17  91\n  51   1  23  44   2  77   1  25  17   6  15   1  22  14   1  30   1  51\n  31  33  51   2  29   1  11  38  11  45  22  17  14   8   8   1  27  14\n   4  20  10  28   1  19  37  13   1  19  19  18  14   6  29  24  17   4\n   1  26  62   1   4  31  13  19   9   1  76  16  31  50  16  48  14  55\n   9   1  27  12  14  12  31  38  48  32  22  14  16  50 136  13  11  23\n   3   1   1   3   8  35  86   7   1   1 150  48  18   7   1  36  51  19\n  26   1   5   5  12   1  39   3  11   1   9   1  57   7  16  40   1   2\n  41   7  28   6   1  44   3  11   9  36   1  44   4   5   1  48   1   1\n  16  12  18 108  53   9  27   7   5  35  15 204   1  39  47  11  10  35\n  31  29   5   1   9  16  23   5   9  31  54   2  29  29  36  12  24  37\n   3  23   1  31  18  23  28   3  14  88  13  18  12  42   3  52  74  66\n  43  23  51  57  49  11  52  14  66   7  28  24 117  11   8   1  21   5\n  20  38  28   9  11   1  19  11  26  43  41  19  41  20  12  19   7  60\n   1  11   4   5  29   6  10  13  27   7  47  47   8   1  35  36   5  12\n  11   1  16  29  47   1   1   9  52  15  27  19  42  31   4   1   1   1\n  20  28   1  47  28  35   1  29  14  41   1  31   1  23  15   1   6  48\n   7   9   1  10  16  62  31   1   1   1  39  49  30  14   9  12  44   3\n  24  13  48  11  15   1  19   1  40  49  50 118  77   1   7  13  27   1\n   6   1  27  21   7  12   1  30   4  18   5  24   2   2  31  16  30  14\n  37  16  23  25  10  42  62  19  32  18  92  47  39   8  22   1   7  13\n  17   7   6  33   4   2  19  25   1   1  22  10  10  12  31   6  39   8\n 104   1   4  47  27   1   1  16  51  20  28  37  22  17  86  87  17   1\n  50   1   1   3   7   6   1   1  27  38  29  36  35   5   9   7  28  11\n  29  12   9  32   8  69  54   8  36  14   1  35  18   9  24 103  12   1\n 120   1  19   1   1  57   1  29   1   9   1  24  27  55   3  38   8  33\n   1   5   4  18  43  21   1  99  31  11  35  26  23  57  12  25   5   1\n  12   9   6  57   1   1   3  22   8  22  53  23  12   5 104  80  41  23\n  36  18  29  21  28   1  34   1  42  22  40  21   1  19   1  13  80  23\n   1  10  24  34  29  23  28  18   1  31  11  24  16  26  12  26   1  34\n  55   1   1  16  19   1  12   5] \n predict [ 10  14  33  81  77  20  14  30  30  18  27   3   6  25  40  88  31  13\n   8  18  10  11  36   7  15  20  29   2  65  43  74  83  25  65  18  92\n  51   3  24  17   7  78   2  27  19  17  15   3   7  15   3  34   3   3\n  32  36  52   3  33   5  13  43  14  17  26  20  22   9  28   4  27  16\n   5   5  12  30   3  20  38  15   2  21  20  21  45   8  31  24  31   5\n   2  27  63   1   6  33  14  20  10   2  81  18  32  51  16  43  15  56\n  11   7  27  16  14  14  33  16  28  34  23  16  17  52 138  15  12  25\n   5   6   2   4   6  25  90   8   2   5   3  48  19   9   4  37  51  20\n  27   5   7  10  14   3  42   4  13   2  10   3  57   7  18  19   6   5\n  43   9   2   9   2  44   5  14  14  38   3  44   5   6   1 104   2   3\n  20  14  19 109  54  12  30  14   6  36  13 194   3  41  48  11  11  35\n  32  30   8   2  11  18  24  10  11  34  57 107  31  30  40  15  25  39\n   4   2   2  63  20  24  29   3  14  93  15  20  15  42   4   6  76  76\n  45  25  52  58  52  12  53  15  67   9  23   2 118   2  10   3  22   6\n  22  40  28  10  12   3  20  12  28  45  41  22  45  24  13  21   8  62\n   3  12   7   6  22  10  14  14  28  12  49  48  10   3  35  37   9  23\n  13   2  18  31  48   2   3  11  53  19  28  20  44  33   8   6   2   2\n  22  34   3  48  23  37   1  31  19  43   5  36   3  25  17   7  22  49\n   9  11   3  16  17  69   2   3   3   3  40  51  33  41  15  13  44   4\n  24  18  49  13  15   2  35   5  40  52  51 119  79   1  12  13  12   3\n  11   2  28  25   9  13   2  31   4  20   8  26  27   5  36  20  31  15\n  38  18  23  26  13  43  46  24  34  19  94  48  56  10  24   3   8  10\n  12   9   8  33  10   6  19  27   2   3  23  11  13  18   9  17  39   9\n 107   4   5  49  30   3   3  17  52  21  40  40  44  17  88   3  21   2\n  52   2   4  13  13  29   2   2  29  38  33  38  37   9  11   9  30  12\n  31  13  10  34   9   3  63  14  37  24   3  36   6  13  24 105  14   3\n  92   4  26   3   2  58   3  30   3  16   3  26  29  12   4  38  10  37\n   3   6   6  20  38  22   2 101  32  13  38  28  25  58  14  26  11   3\n  12  10  29  59   2   4  11  24   9  23   4  16  14   6  10   2  43  25\n  13  20  31  22  32   2  35   2  43  23  42  23   4  21   3  15  57  25\n   4  11  52  37  33  24  29  22   6  32  12  25  17  17  13   5   3  34\n  56   2   9  17  20   3  17   5]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"label [  4  12  33  80  74  18  13  14  28  17  26   1   3  24  39  85  29  25\n   7  16   7  11  34   4  14  19  28   1  22  42  69  80  24  59  17  91\n  51   1  23  44   2  77   1  25  17   6  15   1  22  14   1  30   1  51\n  31  33  51   2  29   1  11  38  11  45  22  17  14   8   8   1  27  14\n   4  20  10  28   1  19  37  13   1  19  19  18  14   6  29  24  17   4\n   1  26  62   1   4  31  13  19   9   1  76  16  31  50  16  48  14  55\n   9   1  27  12  14  12  31  38  48  32  22  14  16  50 136  13  11  23\n   3   1   1   3   8  35  86   7   1   1 150  48  18   7   1  36  51  19\n  26   1   5   5  12   1  39   3  11   1   9   1  57   7  16  40   1   2\n  41   7  28   6   1  44   3  11   9  36   1  44   4   5   1  48   1   1\n  16  12  18 108  53   9  27   7   5  35  15 204   1  39  47  11  10  35\n  31  29   5   1   9  16  23   5   9  31  54   2  29  29  36  12  24  37\n   3  23   1  31  18  23  28   3  14  88  13  18  12  42   3  52  74  66\n  43  23  51  57  49  11  52  14  66   7  28  24 117  11   8   1  21   5\n  20  38  28   9  11   1  19  11  26  43  41  19  41  20  12  19   7  60\n   1  11   4   5  29   6  10  13  27   7  47  47   8   1  35  36   5  12\n  11   1  16  29  47   1   1   9  52  15  27  19  42  31   4   1   1   1\n  20  28   1  47  28  35   1  29  14  41   1  31   1  23  15   1   6  48\n   7   9   1  10  16  62  31   1   1   1  39  49  30  14   9  12  44   3\n  24  13  48  11  15   1  19   1  40  49  50 118  77   1   7  13  27   1\n   6   1  27  21   7  12   1  30   4  18   5  24   2   2  31  16  30  14\n  37  16  23  25  10  42  62  19  32  18  92  47  39   8  22   1   7  13\n  17   7   6  33   4   2  19  25   1   1  22  10  10  12  31   6  39   8\n 104   1   4  47  27   1   1  16  51  20  28  37  22  17  86  87  17   1\n  50   1   1   3   7   6   1   1  27  38  29  36  35   5   9   7  28  11\n  29  12   9  32   8  69  54   8  36  14   1  35  18   9  24 103  12   1\n 120   1  19   1   1  57   1  29   1   9   1  24  27  55   3  38   8  33\n   1   5   4  18  43  21   1  99  31  11  35  26  23  57  12  25   5   1\n  12   9   6  57   1   1   3  22   8  22  53  23  12   5 104  80  41  23\n  36  18  29  21  28   1  34   1  42  22  40  21   1  19   1  13  80  23\n   1  10  24  34  29  23  28  18   1  31  11  24  16  26  12  26   1  34\n  55   1   1  16  19   1  12   5] \n predict [ 10  14  33  81  77  20  14  30  30  18  27   3   6  25  40  88  31  13\n   8  18  10  11  36   7  15  20  29   2  65  43  74  83  25  65  18  92\n  51   3  24  17   7  78   2  27  19   4  15   3   7  15   3  34   3  51\n  32  36  52   3  33   5  13  43  14  17  26  20  15   9  28   4  27  16\n   5  30  12  30   3  20  38  15   2  21  20  21  45   8  31  24  31   5\n   2  27  63   1   6  33  14  20  10   2  81  18  32  51  16  43  15  33\n  11   7  27  16  14  14  33  16  28  34  23  16  17  52 138  15  12  25\n   5   6   2   4  11  25  90   8   2   5   3  48  19   9   4  37  51  20\n  27   5   7  10  14   3  42   4  13   2  10   3  57   7  18  41   6   5\n  43   9   2   9   2  45   5  14  14  38   3  44   5   6   1 104   2   3\n  20  14  19 109  54  12  30  14   6  36  13  60   3  41  48  11  11  35\n  32  30   8   2  11  18  24  10  11  34  57 107  31  30  40  15  25  39\n   4   2   2  63  20  24  29   3  14  93  15  20  15  42   4   6  76  76\n  45  23  52  58  52  12  53  15  67   9  23   2 118   2  12   3  22   6\n  22  40  28  10  12   3  20  12  28  45  41  22  45  21  13  21   8  62\n   3  12   7   6  30  10  14  14  28  12  49  48  10   3  35  37   9  23\n  13   2  18  31  48   2   3  11  53  19  28  20  44  33   8   6   2   2\n  22  34   3  48  23  37   1  31  19  43   5  36   3  25  17   7  22  49\n   9  11   3  16  17  69  32   3   3   3  40  51  33  15  15  13  44   4\n  24  18  49  28  15   2  35   5  40  52  51 119  79   1  12  13  12   3\n  11  75  28  25   9  13   2  31   4  20   8  26  27   2  36  20  31  15\n  38  18  23  26  13  43  46  24  34  19  94  48  56  10  24   3  21  39\n  12   9   8  33  10   6  19  27   2   3  23  11  13  18   9  17  39   9\n 107   4   5  49  30   7   3  17  52  21  40  40  44  17  88  13  21   2\n  52   2   4  13  13  29   2   2  29  38  33  38  37   9  11   9  30  12\n  31  13  10  34   9  72  63  14  37  24   3  36   6  19  24 105  14   3\n  92   4  26   3   2  58   3  30   3  16   3  26  29  57   4  38  10  37\n   3   6   6  20  38  22   2 101  32  13  38  28  25  58  14  26  11   3\n  41  10  29  59   2   4  11  24   9  23  55  26  16   6  10   2  43  25\n   2  20  31  22  32   2  35   2  43  23  42  23   4  21   3  15  57  25\n   4  11  27  37  33  24  29  22   6  32  12  25  17  17  13   5   3  34\n  56   2   9  17  20   3  17   5]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"label [  4  12  33  80  74  18  13  14  28  17  26   1   3  24  39  85  29  25\n   7  16   7  11  34   4  14  19  28   1  22  42  69  80  24  59  17  91\n  51   1  23  44   2  77   1  25  17   6  15   1  22  14   1  30   1  51\n  31  33  51   2  29   1  11  38  11  45  22  17  14   8   8   1  27  14\n   4  20  10  28   1  19  37  13   1  19  19  18  14   6  29  24  17   4\n   1  26  62   1   4  31  13  19   9   1  76  16  31  50  16  48  14  55\n   9   1  27  12  14  12  31  38  48  32  22  14  16  50 136  13  11  23\n   3   1   1   3   8  35  86   7   1   1 150  48  18   7   1  36  51  19\n  26   1   5   5  12   1  39   3  11   1   9   1  57   7  16  40   1   2\n  41   7  28   6   1  44   3  11   9  36   1  44   4   5   1  48   1   1\n  16  12  18 108  53   9  27   7   5  35  15 204   1  39  47  11  10  35\n  31  29   5   1   9  16  23   5   9  31  54   2  29  29  36  12  24  37\n   3  23   1  31  18  23  28   3  14  88  13  18  12  42   3  52  74  66\n  43  23  51  57  49  11  52  14  66   7  28  24 117  11   8   1  21   5\n  20  38  28   9  11   1  19  11  26  43  41  19  41  20  12  19   7  60\n   1  11   4   5  29   6  10  13  27   7  47  47   8   1  35  36   5  12\n  11   1  16  29  47   1   1   9  52  15  27  19  42  31   4   1   1   1\n  20  28   1  47  28  35   1  29  14  41   1  31   1  23  15   1   6  48\n   7   9   1  10  16  62  31   1   1   1  39  49  30  14   9  12  44   3\n  24  13  48  11  15   1  19   1  40  49  50 118  77   1   7  13  27   1\n   6   1  27  21   7  12   1  30   4  18   5  24   2   2  31  16  30  14\n  37  16  23  25  10  42  62  19  32  18  92  47  39   8  22   1   7  13\n  17   7   6  33   4   2  19  25   1   1  22  10  10  12  31   6  39   8\n 104   1   4  47  27   1   1  16  51  20  28  37  22  17  86  87  17   1\n  50   1   1   3   7   6   1   1  27  38  29  36  35   5   9   7  28  11\n  29  12   9  32   8  69  54   8  36  14   1  35  18   9  24 103  12   1\n 120   1  19   1   1  57   1  29   1   9   1  24  27  55   3  38   8  33\n   1   5   4  18  43  21   1  99  31  11  35  26  23  57  12  25   5   1\n  12   9   6  57   1   1   3  22   8  22  53  23  12   5 104  80  41  23\n  36  18  29  21  28   1  34   1  42  22  40  21   1  19   1  13  80  23\n   1  10  24  34  29  23  28  18   1  31  11  24  16  26  12  26   1  34\n  55   1   1  16  19   1  12   5] \n predict [  6  14  33  81  77  20  14  16  30  18  27   3   6  25  40  88  31  13\n   8  18  10  11  36   7  15  20  29   2  65  43  74  83  25  65  18  92\n  51   3  24  17   7  78   2  27  19   4  15   3   7  15   3  34   3  51\n  32  36  52   3  33   5  13  43  14  17  26  20  22   9  28   4  27  16\n   5  30  12  30   3  20  38  15   2  21  20  21  45   8  31  24  31   5\n   2  27  63   1   6  33  14  20  10   2  81  18  32  51  16  43  15  56\n  11   7  27  16  14  14  33  16  28  34  23  16  17  52 138  15  12  25\n   5   6   2   4   6  25  90   8   2   5   3  48  19   9   4  37  51  20\n  27   5   7  10  14   3  42   4  13   2  10   3  57   7  18  41   6   5\n  43   9   2   9   2  45   5  14  14  38   3  44   5   6   1 104   2   3\n  20  14  19 109  54  12  30  14   6  36  13 194   4  41  48  11  11  35\n  32  30  46   2  11  18  24  10  11  34  57 107  31  30  40  15  25  39\n   4   2   2  63  20  24  29   3  14  93  15  20  15  42   4   6  76  76\n  45  25  52  58  52  12  53  15  67   9  23   2 118   2  10   3  22   6\n  22  40  28  10  12   3  20  12  28  45  41  22  45  21  13  32   8  62\n   3  12   7   6  30  10  14  14  28  12  49  48  10   3  35  37   9  23\n  13   2  18  31  48   2   3  11  53  19  28  20  44  33   8  39   2   2\n  22  34   3  48  23  37   1  31  19  43   5  36   3  25  17   7  22  49\n   9  11   3  16  17  69  32   3   3   3  40  51  33  15  15  13  44   4\n  24  18  49  28  15   2  35   5  40  52  51 119  79   1  12  13  12   3\n  11  75  28  25   9  13   2  31   4  20   8  26  27   2  36  20  31  15\n  38  18  23  26  13  43  39  24  34  19  94  48  42  10  24   3   8  39\n  12   9   8  33  10   6  19  27   2   3  23  11  13  18   9  17  39   9\n 107   4   5  49  30   7   3  17  52  21  40  40  44  17  88  13  21   2\n  52   2   4  13  13  29   2   2  29  38  33  38  37   9  11   9  30  12\n  31  13  10  34   9  72  63  14  37  24   3  36   6  19  24 105  14   3\n  92   4  26   3   2  58   3  30   3  16   3  26  29  63   4  38  10  37\n   3   6   6  20  38  22   2 101  32  13  38  28  25  58  14  26  11   3\n  41  10  29  59   2   4  14  24   9  23  55  26  14   6  10   2  43  25\n   2  20  31  22  32   2  35   2  43  23  42  23   4  21   3  15  57  25\n   4  11  27  37  33  24  29  22   6  32  12  25  17  17  13   5   3  34\n  56   2   9  17  20   3  17   5]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"label [  4  12  33  80  74  18  13  14  28  17  26   1   3  24  39  85  29  25\n   7  16   7  11  34   4  14  19  28   1  22  42  69  80  24  59  17  91\n  51   1  23  44   2  77   1  25  17   6  15   1  22  14   1  30   1  51\n  31  33  51   2  29   1  11  38  11  45  22  17  14   8   8   1  27  14\n   4  20  10  28   1  19  37  13   1  19  19  18  14   6  29  24  17   4\n   1  26  62   1   4  31  13  19   9   1  76  16  31  50  16  48  14  55\n   9   1  27  12  14  12  31  38  48  32  22  14  16  50 136  13  11  23\n   3   1   1   3   8  35  86   7   1   1 150  48  18   7   1  36  51  19\n  26   1   5   5  12   1  39   3  11   1   9   1  57   7  16  40   1   2\n  41   7  28   6   1  44   3  11   9  36   1  44   4   5   1  48   1   1\n  16  12  18 108  53   9  27   7   5  35  15 204   1  39  47  11  10  35\n  31  29   5   1   9  16  23   5   9  31  54   2  29  29  36  12  24  37\n   3  23   1  31  18  23  28   3  14  88  13  18  12  42   3  52  74  66\n  43  23  51  57  49  11  52  14  66   7  28  24 117  11   8   1  21   5\n  20  38  28   9  11   1  19  11  26  43  41  19  41  20  12  19   7  60\n   1  11   4   5  29   6  10  13  27   7  47  47   8   1  35  36   5  12\n  11   1  16  29  47   1   1   9  52  15  27  19  42  31   4   1   1   1\n  20  28   1  47  28  35   1  29  14  41   1  31   1  23  15   1   6  48\n   7   9   1  10  16  62  31   1   1   1  39  49  30  14   9  12  44   3\n  24  13  48  11  15   1  19   1  40  49  50 118  77   1   7  13  27   1\n   6   1  27  21   7  12   1  30   4  18   5  24   2   2  31  16  30  14\n  37  16  23  25  10  42  62  19  32  18  92  47  39   8  22   1   7  13\n  17   7   6  33   4   2  19  25   1   1  22  10  10  12  31   6  39   8\n 104   1   4  47  27   1   1  16  51  20  28  37  22  17  86  87  17   1\n  50   1   1   3   7   6   1   1  27  38  29  36  35   5   9   7  28  11\n  29  12   9  32   8  69  54   8  36  14   1  35  18   9  24 103  12   1\n 120   1  19   1   1  57   1  29   1   9   1  24  27  55   3  38   8  33\n   1   5   4  18  43  21   1  99  31  11  35  26  23  57  12  25   5   1\n  12   9   6  57   1   1   3  22   8  22  53  23  12   5 104  80  41  23\n  36  18  29  21  28   1  34   1  42  22  40  21   1  19   1  13  80  23\n   1  10  24  34  29  23  28  18   1  31  11  24  16  26  12  26   1  34\n  55   1   1  16  19   1  12   5] \n predict [ 10  14  33  81  77  20  14  16  30  18  27   3   6  25  40  88  31  13\n   8  18  10  11  36   7  15  20  29   2  65  43  74  83  25  65  18  92\n  51   3  24  17   7  78   2  27  19   4  15   3   7  15   3  34   3  51\n  32  36  52   3  33   5  13  43  14  17  26  20  22   9  28   4  27  16\n   5  30  12  30   3  20  38  15   2  21  20  21  45   8  31  24  31   5\n   2  27  63   1   6  33  14  20  10   2  81  18  32  51  16  43  15  56\n  11   7  27  16  14  14  33  16  28  34  23  16  17  52 138  15  12  25\n   5   6   2   4   6  25  90   8   2   5   3  48  19   9   4  37  51  20\n  27   5   7  10  14   3  42   4  13   2  10   3  57   7  18  41   6   5\n  43   9   2   9   2  45   5  14  14  38   3  44   5   6   1 104   2   3\n  20  14  19 109  54  12  30  14   6  36  13 194   4  41  48  11  11  35\n  32  30  46   2  11  18  24  10  11  34  57 107  31  30  40  15  25  39\n   4   2   2  63  20  24  29   3  14  93  15  20  15  42   4   6  76  76\n  45  25  52  58  52  12  53  15  67   9  23   2 118   2  12   3  22   6\n  22  40  28  10  12   3  20  12  28  45  41  22  45  24  13  21   8  62\n   3  12   7   6  30  10  14  14  28  12  49  48  10   3  35  37   9  23\n  13   2  18  31  48   2   3  11  53  19  28  20  44  33   8  39   2   2\n  22  34   3  48  23  37   1  31  19  43   5  36   3  25  17   7  22  49\n   9  11   3  16  17  69  32   3   3   3  40  51  33  15  15  13  44   4\n  24  18  49  28  15   2  57   5  40  52  51 119  79   1  12  13  12   3\n  11  75  28  25   9  13   2  31   4  20   8  26  27   2  36  20  31  15\n  38  18  23  26  13  43  46  24  34  19  94  48  56  10  24   3   8  39\n  12   9   8  33  10   6  19  27   2   3  23  11  13  18   9  17  39   9\n 107   4   5  49  30   7   3  17  52  21  40  40  44  17  88   3  21   2\n  52   2   4  13  13  29 143   2  29  38  33  38  37   9  11   9  30  12\n  31  13  10  34   9  72  63  14  37  24   3  36   6  19  24 105  14   3\n  92   4  26   3   2  58   3  30   3  16   3  26  29  63   4  38  10  37\n   3   6   6  20  38  22   2 101  32  13  38  28  25  58  14  26  11   3\n  41  10  29  59   2   4  11  24   9  23  55  26  16   6  10   2  43  25\n   2  20  31  22  32   2  35   2  43  23  42  23   4  21   3  15  57  25\n   4  11  27  37  33  24  29  22   6  32  12  25  17  17  13   5   3  34\n  56   2   9  17  20   3  17   5]\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=7965, training_loss=0.5992311342255424, metrics={'train_runtime': 2671.7899, 'train_samples_per_second': 23.847, 'train_steps_per_second': 2.981, 'total_flos': 8324261427717120.0, 'train_loss': 0.5992311342255424, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(\"/kaggle/model\")","metadata":{"execution":{"iopub.status.busy":"2024-01-10T03:40:30.148779Z","iopub.execute_input":"2024-01-10T03:40:30.149115Z","iopub.status.idle":"2024-01-10T03:40:30.978372Z","shell.execute_reply.started":"2024-01-10T03:40:30.149075Z","shell.execute_reply":"2024-01-10T03:40:30.977325Z"},"trusted":true},"execution_count":12,"outputs":[]}]}