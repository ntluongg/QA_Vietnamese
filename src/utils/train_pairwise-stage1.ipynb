{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2420414-a6cf-49e5-98a5-ba2704851b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/xserver/xapps/miniconda3/envs/anhnt/lib/python3.8/site-packages/huggingface_hub/snapshot_download.py:6: FutureWarning: snapshot_download.py has been made private and will no longer be available from version 0.11. Please use `from huggingface_hub import snapshot_download` to import the only public function in this module. Other members of the file may be changed without a deprecation notice.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyvi.ViTokenizer import tokenize\n",
    "from transformers import AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import DataCollatorWithPadding\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import math\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4d6b19-03e5-429f-98b0-80ee9947a64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTH_TOKEN = \"insert_your_huggingface_token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac6f052-a913-4cc5-81e6-e5faa1e63bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> sinh viên đại học bách khoa hà nội</s>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('nguyenvulebinh/vi-mrc-base', use_auth_token=AUTH_TOKEN)\n",
    "print(tokenizer.decode(tokenizer.encode(\"sinh viên đại học bách khoa hà nội\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee27e41a-d39a-4974-aea2-bfa4528869a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from glob import glob \n",
    "import re \n",
    "from nltk import word_tokenize as lib_tokenizer \n",
    " \n",
    "dict_map = dict({}) \n",
    " \n",
    "def word_tokenize(text): \n",
    "    global dict_map \n",
    "    words = text.split() \n",
    "    words_norm = [] \n",
    "    for w in words: \n",
    "        if dict_map.get(w, None) is None: \n",
    "            dict_map[w] = ' '.join(lib_tokenizer(w)).replace('``', '\"').replace(\"''\", '\"') \n",
    "        words_norm.append(dict_map[w]) \n",
    "    return words_norm \n",
    " \n",
    "def strip_answer_string(text): \n",
    "    text = text.strip() \n",
    "    while text[-1] in '.,/><;:\\'\"[]{}+=-_)(*&^!~`': \n",
    "        if text[0] != '(' and text[-1] == ')' and '(' in text: \n",
    "            break \n",
    "        if text[-1] == '\"' and text[0] != '\"' and text.count('\"') > 1: \n",
    "            break \n",
    "        text = text[:-1].strip() \n",
    "    while text[0] in '.,/><;:\\'\"[]{}+=-_)(*&^!~`': \n",
    "        if text[0] == '\"' and text[-1] != '\"' and text.count('\"') > 1: \n",
    "            break \n",
    "        text = text[1:].strip() \n",
    "    text = text.strip() \n",
    "    return text \n",
    " \n",
    "def strip_context(text): \n",
    "    text = text.replace('\\n', ' ') \n",
    "    text = re.sub(r'\\s+', ' ', text) \n",
    "    text = text.strip() \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff9f90cf-a849-4e19-aecd-d6ee09b4b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./processed/train_stage1_ranking.csv\")\n",
    "df1.text = df1.text.apply(lambda x: \" \".join(word_tokenize(strip_context(x))))\n",
    "df1.question = df1.question.apply(lambda x: \" \".join(word_tokenize(strip_context(x))))\n",
    "df = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f791022-2721-47ce-902e-480d4e8cf851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoConfig\n",
    "\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "class PairwiseModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(PairwiseModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name, use_auth_token=AUTH_TOKEN)\n",
    "        self.config = AutoConfig.from_pretrained(model_name, use_auth_token=AUTH_TOKEN)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.fc = nn.Linear(768, 1)\n",
    "        \n",
    "    def forward(self, ids, masks):\n",
    "        out = self.model(input_ids=ids,\n",
    "                           attention_mask=masks,\n",
    "                           output_hidden_states=False).last_hidden_state\n",
    "        out = out[:,0]\n",
    "        outputs = self.fc(out)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feb3f593-e019-4eb3-8117-e989e9fa0ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SiameseDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.content1 = tokenizer.batch_encode_plus(list(df.question.apply(lambda x: x.replace(\"_\",\" \")).values), max_length=max_length, truncation=True)[\"input_ids\"]\n",
    "        self.content2 = tokenizer.batch_encode_plus(list(df.text.apply(lambda x: x.replace(\"_\",\" \")).values), max_length=max_length, truncation=True)[\"input_ids\"]\n",
    "        self.targets = self.df.label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'ids1': torch.tensor(self.content1[index], dtype=torch.long),\n",
    "            'ids2': torch.tensor(self.content2[index][1:], dtype=torch.long),\n",
    "            'target': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b90d52d-6874-4d10-b615-9f24cfefbb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token_id = tokenizer.pad_token_id\n",
    "def collate_fn(batch):\n",
    "    ids = [torch.cat([x[\"ids1\"], x[\"ids2\"]]) for x in batch]\n",
    "    targets = [x[\"target\"] for x in batch]\n",
    "    max_len = np.max([len(x) for x in ids])\n",
    "    masks = []\n",
    "    for i in range(len(ids)):\n",
    "        if len(ids[i]) < max_len:\n",
    "            ids[i]= torch.cat((ids[i], torch.tensor([pad_token_id,]*(max_len - len(ids[i])),dtype=torch.long)))\n",
    "        masks.append(ids[i] != pad_token_id)\n",
    "    # print(tokenizer.decode(ids[0]))\n",
    "    outputs = {\n",
    "        \"ids\": torch.vstack(ids),\n",
    "        \"masks\": torch.vstack(masks),\n",
    "        \"target\": torch.vstack(targets).view(-1)\n",
    "    }\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acfffa17-cd3d-467b-8d6d-52f47e188d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8ed6881-76e8-48db-9cf3-7e2eebfaf103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_scheduler(model, num_train_steps):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.001,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "\n",
    "    opt = AdamW(optimizer_parameters, lr=3e-5)\n",
    "    sch = get_linear_schedule_with_warmup(\n",
    "        opt,\n",
    "        num_warmup_steps=int(0.05*num_train_steps),\n",
    "        num_training_steps=num_train_steps,\n",
    "        last_epoch=-1,\n",
    "    )\n",
    "    return opt, sch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f89ad61-1285-44bf-bfe3-9822b0667f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b73add95-d422-4a15-9280-781d350c9f38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     3     6 ... 20096 20102 20105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nguyenvulebinh/vi-mrc-base were not used when initializing RobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at nguyenvulebinh/vi-mrc-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/xserver/xapps/miniconda3/envs/anhnt/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4fe68691cd4093af61eb5d56774267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5026 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.9051274178692048\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5026 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.9673033344124311\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5026 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.9820051413881747\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5026 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.990593577684074\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5026 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.9928664072632944\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "epochs = 5\n",
    "accumulation_steps = 8\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "error_ids = None\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(df, df.label)):\n",
    "    if fold != 0:\n",
    "        break\n",
    "    print(test_index)\n",
    "    model = PairwiseModel('nguyenvulebinh/vi-mrc-base')\n",
    "    # model.load_state_dict(torch.load(f\"./outputs/pairwise_v2.bin\"))\n",
    "    model.cuda()\n",
    "    train_df = df\n",
    "    # train_df = df.iloc[train_index].reset_index(drop=True)\n",
    "    val_df = df.iloc[test_index].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = SiameseDataset(train_df, tokenizer, 384)\n",
    "    valid_dataset = SiameseDataset(val_df, tokenizer, 384)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, collate_fn=collate_fn,\n",
    "                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=32, collate_fn=collate_fn,\n",
    "                              num_workers=2, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    num_train_steps = len(train_loader) * epochs // accumulation_steps\n",
    "    optimizer, scheduler = optimizer_scheduler(model, num_train_steps)\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        bar = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "        for step, data in bar:\n",
    "            ids = data[\"ids\"].cuda()\n",
    "            # for x in ids:\n",
    "            #     print(tokenizer.decode(x))\n",
    "            masks = data[\"masks\"].cuda()\n",
    "            target = data[\"target\"].cuda()\n",
    "            # with torch.cuda.amp.autocast():\n",
    "            preds = model(ids, masks)\n",
    "            # print(preds.view(-1))\n",
    "            loss = loss_fn(preds.view(-1), target.view(-1))\n",
    "            loss /= accumulation_steps\n",
    "            loss.backward()\n",
    "            if (step + 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                # scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                scheduler.step()\n",
    "            bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            bar = tqdm(enumerate(valid_loader), total=len(valid_loader), leave=False)\n",
    "            targets = []\n",
    "            all_preds = []\n",
    "            for step, data in bar:\n",
    "                ids = data[\"ids\"].cuda()\n",
    "                masks = data[\"masks\"].cuda()\n",
    "                target = data[\"target\"].cuda()\n",
    "                preds = torch.sigmoid(model(ids, masks))\n",
    "                all_preds.extend(preds.cpu().view(-1).numpy())\n",
    "                targets.extend(target.cpu().view(-1).numpy())\n",
    "            all_preds = np.array(all_preds)\n",
    "            targets = np.array(targets)\n",
    "            print(f\"F1 {f1_score(targets, all_preds > 0.5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bffda736-8860-4dc5-b600-5a49e3fb6327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.9948018193632229\n"
     ]
    }
   ],
   "source": [
    "print(f\"F1 {recall_score(np.array(targets), np.array(all_preds) > 0.5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "544a8ccc-632d-4237-98c8-545946265bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"./outputs/pairwise_v2.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b3c0ad-ad16-4178-af68-15405bfc8ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
